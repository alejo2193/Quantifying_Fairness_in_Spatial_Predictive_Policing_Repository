{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Allow us to load `open_cp` without installing\n",
    "import sys, os.path\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreation of SaTScan analysis\n",
    "\n",
    "Whereby we try to recreate the output of SatScan for the NYCFever data set.\n",
    "\n",
    "Download a copy of SaTScan from www.satscan.org and copy the files `NYCFever.geo` `NYCFever.cas` to this directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pyproj\n",
    "proj = pyproj.Proj(init=\"epsg:2260\")# New York\n",
    "\n",
    "coord_lookup = dict()\n",
    "raw_coord_lookup = dict()\n",
    "with open(\"NYCfever.geo\") as geofile:\n",
    "    for line in geofile:\n",
    "        idcode, lat, lon = line.split()\n",
    "        lon, lat = float(lon), float(lat)\n",
    "        x, y = proj(lon, lat)\n",
    "        if idcode in coord_lookup:\n",
    "            raise Exception(\"Key {} specified twice\".format(idcode))\n",
    "        coord_lookup[idcode] = (x,y)\n",
    "        raw_coord_lookup[idcode] = (lon,lat)\n",
    "        \n",
    "def get_zip_code(x,y):\n",
    "    for idcode in coord_lookup:\n",
    "        xx, yy = coord_lookup[idcode]\n",
    "        if ((x-xx)**2 + (y-yy)**2 < 1e-6):\n",
    "            return idcode\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(194, 194)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "data = []\n",
    "raw_data = []\n",
    "with open(\"NYCfever.cas\") as casefile:\n",
    "    for line in casefile:\n",
    "        idcode, cases, date = line.split()\n",
    "        date = datetime.datetime.strptime(date, \"%Y/%m/%d\")\n",
    "        cases = int(cases)\n",
    "        assert(cases == 1)\n",
    "        x, y = coord_lookup[idcode]\n",
    "        data.append((date, x, y))\n",
    "        raw_data.append((date, idcode))\n",
    "\n",
    "len(data), len(raw_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(datetime.datetime(2001, 11, 1, 0, 0), datetime.datetime(2001, 11, 24, 0, 0))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Date range\n",
    "min(d for d,_,_ in data), max(d for d,_,_ in data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nImktbAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f576c4daf60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([x/1000 for d,x,y in data])\n",
    "y = np.array([y/1000 for d,x,y in data])\n",
    "\n",
    "dx = np.random.random(size=len(x)) * 1\n",
    "dy = np.random.random(size=len(y)) * 1\n",
    "\n",
    "_ = plt.scatter(x+dx, y+dy, marker=\"+\", linewidth=1, color=\"black\", alpha=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a \"prospective scan\", we single out only those clusters which last until the final day.  The default settings in the test script look for clusters up to a maximum size of 50% of the events or 3km (radius or diameter?)  The temporal size is between 1 and 7 days.\n",
    "\n",
    "The expected clusters are:\n",
    "\n",
    "        1.Location IDs included.: 11418, 11415, 11419, 11435, 11416, 11421, 11451, 11375, 11417\n",
    "          Coordinates / radius..: (40.699240 N, 73.831760 W) / 2.90 km\n",
    "          Time frame............: 2001/11/22 to 2001/11/24\n",
    "          Number of cases.......: 4\n",
    "          Expected cases........: 0.67\n",
    "          Observed / expected...: 5.97\n",
    "          Test statistic........: 3.845418\n",
    "          P-value...............: 0.229\n",
    "          Recurrence interval...: 4 days\n",
    "\n",
    "        2.Location IDs included.: 11372\n",
    "          Coordinates / radius..: (40.751460 N, 73.883070 W) / 0 km\n",
    "          Time frame............: 2001/11/24 to 2001/11/24\n",
    "          Number of cases.......: 2\n",
    "          Expected cases........: 0.16\n",
    "          Observed / expected...: 12.13\n",
    "          Test statistic........: 3.164201\n",
    "          P-value...............: 0.514\n",
    "          Recurrence interval...: 2 days\n",
    "\n",
    "        3.Location IDs included.: 10472\n",
    "          Coordinates / radius..: (40.829960 N, 73.864640 W) / 0 km\n",
    "          Time frame............: 2001/11/23 to 2001/11/24\n",
    "          Number of cases.......: 2\n",
    "          Expected cases........: 0.29\n",
    "          Observed / expected...: 6.81\n",
    "          Test statistic........: 2.137259\n",
    "          P-value...............: 0.959\n",
    "          Recurrence interval...: 1 day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running a retrospective analysis instead yields the following.  Notice that _none_ of these clusters exist until the end of time, suggesting that it is _not_ the case that the \"prospective\" analysis runs the same test and then only resports certain clusters.  Rather, it seems that it limits its search to only clusters ending at the end of time.\n",
    "\n",
    "    1.Location IDs included.: 10454, 10455, 10451, 10035, 10037, 10030, 10029, 10456\n",
    "      Coordinates / radius..: (40.805490 N, 73.917000 W) / 2.70 km\n",
    "      Time frame............: 2001/11/8 to 2001/11/8\n",
    "      Number of cases.......: 5\n",
    "      Expected cases........: 0.40\n",
    "      Observed / expected...: 12.60\n",
    "      Test statistic........: 8.119521\n",
    "      P-value...............: 0.0087\n",
    "\n",
    "    2.Location IDs included.: 11379, 11374, 11373\n",
    "      Coordinates / radius..: (40.716920 N, 73.880330 W) / 2.07 km\n",
    "      Time frame............: 2001/11/10 to 2001/11/11\n",
    "      Number of cases.......: 4\n",
    "      Expected cases........: 0.46\n",
    "      Observed / expected...: 8.62\n",
    "      Test statistic........: 5.113791\n",
    "      P-value...............: 0.496\n",
    "\n",
    "    3.Location IDs included.: 11418, 11415, 11419, 11435, 11416, 11421, 11451, 11375, 11417\n",
    "      Coordinates / radius..: (40.699240 N, 73.831760 W) / 2.90 km\n",
    "      Time frame............: 2001/11/22 to 2001/11/23\n",
    "      Number of cases.......: 4\n",
    "      Expected cases........: 0.46\n",
    "      Observed / expected...: 8.62\n",
    "      Test statistic........: 5.113791\n",
    "      P-value...............: 0.496\n",
    "\n",
    "    4.Location IDs included.: 11434\n",
    "      Coordinates / radius..: (40.676220 N, 73.775200 W) / 0 km\n",
    "      Time frame............: 2001/11/16 to 2001/11/16\n",
    "      Number of cases.......: 2\n",
    "      Expected cases........: 0.072\n",
    "      Observed / expected...: 27.71\n",
    "      Test statistic........: 4.725675\n",
    "      P-value...............: 0.760\n",
    "\n",
    "    5.Location IDs included.: 10304, 10301\n",
    "      Coordinates / radius..: (40.608000 N, 74.093490 W) / 1.84 km\n",
    "      Time frame............: 2001/11/15 to 2001/11/15\n",
    "      Number of cases.......: 2\n",
    "      Expected cases........: 0.072\n",
    "      Observed / expected...: 27.71\n",
    "      Test statistic........: 4.725675\n",
    "      P-value...............: 0.760\n",
    "\n",
    "    6.Location IDs included.: 10460, 10457, 10462\n",
    "      Coordinates / radius..: (40.843800 N, 73.879980 W) / 1.83 km\n",
    "      Time frame............: 2001/11/9 to 2001/11/9\n",
    "      Number of cases.......: 3\n",
    "      Expected cases........: 0.25\n",
    "      Observed / expected...: 11.88\n",
    "      Test statistic........: 4.696100\n",
    "      P-value...............: 0.767\n",
    "\n",
    "    7.Location IDs included.: 11210, 11230, 11226\n",
    "      Coordinates / radius..: (40.625050 N, 73.945750 W) / 2.49 km\n",
    "      Time frame............: 2001/11/5 to 2001/11/5\n",
    "      Number of cases.......: 3\n",
    "      Expected cases........: 0.37\n",
    "      Observed / expected...: 8.08\n",
    "      Test statistic........: 3.658474\n",
    "      P-value...............: 0.999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing all possible space regions\n",
    "\n",
    "For each point, we look at disks centred at that point with radii chosen to just be large enough to encompass 0, 1, 2 and so on many closest points.  This leads to some disks which contain the same point, so we construct just the unique points.\n",
    "\n",
    "We also apply the constraints that no disc can contain more than 50% of the events (which is different from 50% of the points) and that no disc can have a radii greater than 3km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_locations = []\n",
    "\n",
    "for _, x, y in data:\n",
    "    if any((x-xx)**2 + (y-yy)**2 < 1e-6  for (xx, yy) in all_locations):\n",
    "        continue\n",
    "    all_locations.append( (x,y) )\n",
    "\n",
    "len(all_locations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "Disc = namedtuple(\"Disc\", [\"x\", \"y\", \"r\"])\n",
    "\n",
    "discs = []\n",
    "for i, (x,y) in enumerate(all_locations):\n",
    "    dists = [ np.sqrt((x-xx)**2+(y-yy)**2) for j, (xx,yy) in enumerate(all_locations) ]\n",
    "    dists = [r for r in dists if r<=3000]\n",
    "    dists.sort()\n",
    "    if len(dists) > 1:\n",
    "        mingap = min(x-y for x,y in zip(dists[1:], dists))\n",
    "        delta = min(0.01, mingap/2)\n",
    "        radii = [r + delta for r in dists]\n",
    "    else:\n",
    "        radii = [0]\n",
    "    discs.extend( Disc(x,y,r) for r in radii )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(270, 311)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find discs which actually contain the same points\n",
    "\n",
    "def locations_in(x,y,r):\n",
    "    return [ i for i,(xx,yy) in enumerate(all_locations) if (x-xx)**2 + (y-yy)**2 <= r*r ]\n",
    "\n",
    "space_regions = dict()\n",
    "for disc in discs:\n",
    "    key = frozenset(locations_in(*disc))\n",
    "    if key not in space_regions:\n",
    "        space_regions[key] = []\n",
    "    space_regions[key].append(disc)\n",
    "\n",
    "# This doesn't do anything for this data set\n",
    "space_regions = { key : space_regions[key] for key in space_regions if len(key)*2 <= len(data) }\n",
    "    \n",
    "len(space_regions), len(discs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Replace discs by the shorter list, and compute counts\n",
    "\n",
    "discs = [ space_regions[key][0] for key in space_regions ]\n",
    "space_counts = []\n",
    "for disc in discs:\n",
    "    rr = disc.r ** 2\n",
    "    space_counts.append(sum(\n",
    "        (x-disc.x)**2 + (y-disc.y)**2 <= rr\n",
    "        for date, x, y in data ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find the cluster which SaTScan finds\n",
    "\n",
    "As a sanity check, let's check that one of our discs agrees with the cluster which SaTScan finds!\n",
    "The first cluster which SaTScan finds is:\n",
    "\n",
    "    Location IDs included.: 11418, 11415, 11419, 11435, 11416, 11421, 11451, 11375, 11417\n",
    "    Coordinates / radius..: (40.699240 N, 73.831760 W) / 2.90 km\n",
    "    \n",
    "This is a bit misleading, as _not all zip codes appear in the case file data!_\n",
    "\n",
    "(This location is centred on 11418.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11419 not found\n",
      "11416 not found\n",
      "11451 not found\n",
      "11375 not found\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['11418', '11415', '11435', '11421', '11417']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expected = [11418, 11415, 11419, 11435, 11416, 11421, 11451, 11375, 11417]\n",
    "for zipcode in expected:\n",
    "    if not any(z == str(zipcode) for _,z in raw_data):\n",
    "        print(\"{} not found\".format(zipcode))\n",
    "expected = [ str(zipcode) for zipcode in expected\n",
    "           if any(z == str(zipcode) for _,z in raw_data) ]\n",
    "expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['11421', '11417', '11415', '11418', '11435']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = proj(-73.831760, 40.699240)\n",
    "radius = 2903 # 2900 doesn't work\n",
    "pts = [ (xx,yy) for xx, yy in all_locations\n",
    "       if (x-xx)**2 + (y-yy)**2 <= radius**2 ]\n",
    "zips = [ get_zip_code(xx,yy) for xx,yy in pts ]\n",
    "zips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we use a disk of radius 2900 then we miss 11417.  This is either due to my code using a projection, while SaTScan apparently works with great circles on an (idealised?) sphere; or it could be down to rounding 2903m to 2.90km."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2902.8915483554074"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xx, yy = coord_lookup[\"11417\"]\n",
    "np.sqrt((x-xx)**2 + (y-yy)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[50, 45, 59, 26, 28]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Find the indices into `all_locations` for these zip codes\n",
    "expected_indexes = [all_locations.index(coord_lookup[zipcode]) for zipcode in expected]\n",
    "expected_indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Disc(x=206471.83133200672, y=207365.95278645432, r=2902.9015483554076)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finally find the disc!\n",
    "space_regions[frozenset(expected_indexes)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constructing all possible time regions\n",
    "\n",
    "For a \"prospective\" scan we look only at intervals which end on the final date, and are between 1 and 7 days in size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_date = max(d for d,_,_ in data)\n",
    "time_regions = [(last_date - datetime.timedelta(days=i), last_date)\n",
    "               for i in range(7)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 19, 26, 35, 50, 55, 58]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_counts = []\n",
    "for time_region in time_regions:\n",
    "    start, end = time_region\n",
    "    count = sum(d >= start and d <= end for d,_,_ in data)\n",
    "    time_counts.append(count)\n",
    "    \n",
    "time_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the statistic for each region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def count(disc, time_region, data=data):\n",
    "    start, end = time_region\n",
    "    rr = disc.r ** 2\n",
    "    return sum(\n",
    "        date >= start and date <= end and\n",
    "        (x-disc.x)**2 + (y-disc.y)**2 <= rr\n",
    "        for date, x, y in data)\n",
    "\n",
    "def log_likelihood(c, mu):\n",
    "    # Shouldn't be called with c=0\n",
    "    return c * (np.log(c) - np.log(mu))\n",
    "\n",
    "def statistic(c, N, space_count, time_count):\n",
    "    mu = space_count * time_count / N\n",
    "    return log_likelihood(c, mu) + log_likelihood(N-c, N-mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Comb = namedtuple(\"Comb\", [\"space_count\", \"time_count\", \"data_count\", \"stat\"])\n",
    "\n",
    "def make_combinatorial(data):\n",
    "    N = len(data)\n",
    "    combinatorial = dict()\n",
    "    for space_index, disc in enumerate(discs):\n",
    "        space_count = space_counts[space_index]\n",
    "        for time_index, time_region in enumerate(time_regions):\n",
    "            key = (disc, time_region)\n",
    "            time_count = time_counts[time_index]\n",
    "            expected_count = space_count * time_count / N\n",
    "            actual_count = count(key[0], key[1], data)\n",
    "            if actual_count > expected_count:\n",
    "                s = statistic(actual_count, N, space_count, time_count)\n",
    "            else:\n",
    "                s = -np.inf\n",
    "            combinatorial[key] = Comb(space_count, time_count, actual_count, s)\n",
    "    return combinatorial\n",
    "            \n",
    "combinatorial = make_combinatorial(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clusters = { key : combinatorial[key] for key in combinatorial\n",
    "           if combinatorial[key].stat > -np.inf }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8454183710604433"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(comb.stat for comb in clusters.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{(Disc(x=206471.83133200672, y=207365.95278645432, r=2902.9015483554076),\n",
       "  (datetime.datetime(2001, 11, 22, 0, 0),\n",
       "   datetime.datetime(2001, 11, 24, 0, 0))): Comb(space_count=5, time_count=26, data_count=4, stat=3.8454183710604433)}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = {key:clusters[key] for key in clusters if clusters[key].stat > 3.8}\n",
    "best_key = next(iter(best))\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Zip code of centre of disc: 11418\n",
      "Lon/Lat coords: (-73.83176, 40.69924)\n",
      "Expected count: 0.6701030927835051\n"
     ]
    }
   ],
   "source": [
    "zipcode = get_zip_code(best_key[0].x, best_key[0].y)\n",
    "print(\"Zip code of centre of disc:\", zipcode)\n",
    "print(\"Lon/Lat coords:\", raw_coord_lookup[zipcode])\n",
    "print(\"Expected count:\",5 * 26 / len(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we compare this to what we expect:\n",
    "\n",
    "    1.Location IDs included.: 11418, 11415, 11419, 11435, 11416, 11421, 11451, 11375, 11417\n",
    "      Coordinates / radius..: (40.699240 N, 73.831760 W) / 2.90 km\n",
    "      Time frame............: 2001/11/22 to 2001/11/24\n",
    "      Number of cases.......: 4\n",
    "      Expected cases........: 0.67\n",
    "      Observed / expected...: 5.97\n",
    "      Test statistic........: 3.845418\n",
    "      P-value...............: 0.229\n",
    "      Recurrence interval...: 4 days\n",
    "      \n",
    "Then we seem to get a good match!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find other clusters\n",
    "\n",
    "What we expect (and what find!)\n",
    "\n",
    "    2.Location IDs included.: 11372\n",
    "      Coordinates / radius..: (40.751460 N, 73.883070 W) / 0 km\n",
    "      Time frame............: 2001/11/24 to 2001/11/24\n",
    "      Test statistic........: 3.164201\n",
    "      \n",
    "    3.Location IDs included.: 10472\n",
    "      Coordinates / radius..: (40.829960 N, 73.864640 W) / 0 km\n",
    "      Time frame............: 2001/11/23 to 2001/11/24\n",
    "      Test statistic........: 2.137259"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def discs_intersect(d1, d2):\n",
    "    dist = np.sqrt((d1.x - d2.x)**2 + (d1.y - d2.y)**2)\n",
    "    return dist <= d1.r + d2.r\n",
    "\n",
    "def discs_contain_points_in_intersection(d1, d2):\n",
    "    in1 = set(i for i,(d,x,y) in enumerate(data) if (x-d1.x)**2 + (y-d1.y)**2 <= d1.r**2)\n",
    "    in2 = set(i for i,(d,x,y) in enumerate(data) if (x-d1.x)**2 + (y-d1.y)**2 <= d1.r**2)\n",
    "    return len(in1.intersection(in2)) > 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "best_keys = {best_key}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next best key: (Disc(x=202094.94773067575, y=213132.66867960128, r=0.01), (datetime.datetime(2001, 11, 24, 0, 0), datetime.datetime(2001, 11, 24, 0, 0)))\n",
      "With statistic 3.16420115704\n",
      "Zip code of centre of disc: 11372\n",
      "Lon/Lat coords: (-73.88307, 40.75146)\n",
      "Next best key: (Disc(x=203588.077360351, y=221860.39352195128, r=0.01), (datetime.datetime(2001, 11, 23, 0, 0), datetime.datetime(2001, 11, 24, 0, 0)))\n",
      "With statistic 2.13725887188\n",
      "Zip code of centre of disc: 10472\n",
      "Lon/Lat coords: (-73.86464, 40.82996)\n"
     ]
    }
   ],
   "source": [
    "for _ in range(2):\n",
    "    cluster_keys = [key for key in clusters.keys()\n",
    "        if not any(discs_intersect(bkey[0], key[0]) for bkey in best_keys)]\n",
    "    max_stat = max(clusters[key].stat for key in cluster_keys)\n",
    "    next_best = {key:clusters[key] for key in cluster_keys if clusters[key].stat >= max_stat-0.001}\n",
    "    next_key = next(iter(next_best))\n",
    "    print(\"Next best key:\", next_key)\n",
    "    print(\"With statistic\", max_stat)\n",
    "    zipcode = get_zip_code(next_key[0].x, next_key[0].y)\n",
    "    print(\"Zip code of centre of disc:\", zipcode)\n",
    "    print(\"Lon/Lat coords:\", raw_coord_lookup[zipcode])\n",
    "    best_keys.add(next_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Computing p-values\n",
    "\n",
    "The monte carlo simuation stuff only enters the picture when we wish to compute p-values.  To do this, we randomly shuffle the dates and recompute the largest value of the statistic for _any_ cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def make_random_data(data):\n",
    "    dates = np.array([d for d,x,y in data])\n",
    "    np.random.shuffle(dates)\n",
    "    return [(d,x,y) for (d,(_,x,y)) in zip(dates, data)]\n",
    "\n",
    "max_stats = []\n",
    "for _ in range(999):\n",
    "    new_data = make_random_data(data)\n",
    "    new_comb = make_combinatorial(new_data)\n",
    "    max_stats.append(max(x.stat for x in new_comb.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 403, 989)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_stats = np.sort(max_stats)\n",
    "sum(max_stats >= 3.84), sum(max_stats >= 3.16), sum(max_stats >= 2.13)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I ran SaTScan with 99999 Monte Carlo loops, and it reported the following critical values (which is an output option):\n",
    "\n",
    "    Standard Monte Carlo Critical Values:\n",
    "    ... 0.00001: 9.386483\n",
    "    .... 0.0001: 8.297913\n",
    "    ..... 0.001: 7.121381\n",
    "    ...... 0.01: 5.887987\n",
    "    ...... 0.05: 4.752877\n",
    "    \n",
    "With just 999 loops, we get:\n",
    "\n",
    "    Standard Monte Carlo Critical Values:\n",
    "    ..... 0.001: 9.386483\n",
    "    ...... 0.01: 5.920812\n",
    "    ...... 0.05: 4.752877\n",
    "    \n",
    "You can also ask the program to save the values as the file `NYCFever.llr.txt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5.8879867933947256, 4.7109645229397525)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_stats[-10], max_stats[-50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'NYCfever.llr.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-0cea001df79d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"NYCfever.llr.txt\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mllr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mllr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'NYCfever.llr.txt'"
     ]
    }
   ],
   "source": [
    "with open(\"NYCfever.llr.txt\") as llr:\n",
    "    stats = [float(line) for line in llr]\n",
    "stats = np.sort(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(stats)\n",
    "plt.plot(max_stats)\n",
    "plt.legend([\"SaTScan\", \"Us\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use our library code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import open_cp\n",
    "import open_cp.stscan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(open_cp.stscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps, xcs, ycs = tuple(zip(*data))\n",
    "timestamps, xcs, ycs = open_cp.data.order_by_time(timestamps, xcs, ycs)\n",
    "points = open_cp.TimedPoints.from_coords(timestamps, xcs, ycs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check we construct the same discs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def close(centre, d):\n",
    "    return (centre[0] - d.x)**2 + (centre[1] - d.y)**2 < 0.00001\n",
    "\n",
    "def inside(pt, d):\n",
    "    return (pt[0] - d.x)**2 + (pt[1] - d.y)**2 <= d.r**2\n",
    "\n",
    "def contents(d, points):\n",
    "    s = set()\n",
    "    for i, pt in enumerate(points.T):\n",
    "        if inside(pt, d):\n",
    "            s.add(i)\n",
    "    return frozenset(s)\n",
    "\n",
    "print(\"We have {} discs from above\".format(len(discs)))\n",
    "discs_to_contents = [ contents(d, points.coords) for d in discs ]\n",
    "    \n",
    "discs[0], discs_to_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_discs = open_cp.stscan._possible_space_clusters(points.coords, 3000)\n",
    "print(\"We have {} discs from the library code\".format(len(our_discs)))\n",
    "our_discs_to_contents = [contents(Disc(d.centre[0], d.centre[1], d.radius), points.coords) for d in our_discs]\n",
    "\n",
    "our_discs[0], our_discs_to_contents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i, contents in enumerate(discs_to_contents):\n",
    "    if contents not in our_discs_to_contents:\n",
    "        raise Exception(\"Missing {} from {}\".format(contents, discs[i]))\n",
    "        \n",
    "for contents in our_discs_to_contents:\n",
    "    if contents not in discs_to_contents:\n",
    "        raise Exception(\"(2) Missing {}\".format(contents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check we construct the same time regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "end_time = points.timestamps[-1].astype(datetime.datetime)\n",
    "start_times = open_cp.stscan._possible_start_times(points.timestamps, datetime.timedelta(days=6), end_time)\n",
    "\n",
    "our_time_regions = [(st.astype(datetime.datetime), end_time) for st in start_times]\n",
    "\n",
    "assert(set(time_regions) == set(our_time_regions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check we find the same first 3 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = open_cp.stscan.STSTrainer()\n",
    "trainer.geographic_population_limit = 0.5\n",
    "trainer.geographic_radius_limit = 3000\n",
    "trainer.time_population_limit = 1.0\n",
    "trainer.time_max_interval = datetime.timedelta(days=6)\n",
    "trainer.data = points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = trainer.predict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best cluster should be:\n",
    "\n",
    "     {(Disc(x=206471.83133200672, y=207365.95278645432, r=2902.9015483554076),\n",
    "      (datetime.datetime(2001, 11, 22, 0, 0),\n",
    "       datetime.datetime(2001, 11, 24, 0, 0))): Comb(space_count=5, time_count=26, data_count=4, stat=3.8454183710604433)}\n",
    "       \n",
    "Followed by:\n",
    "\n",
    "    Next best key: (Disc(x=202094.94773067575, y=213132.66867960128, r=0.01), (datetime.datetime(2001, 11, 24, 0, 0), datetime.datetime(2001, 11, 24, 0, 0)))\n",
    "    With statistic 3.16420115704\n",
    "    Next best key: (Disc(x=203588.077360351, y=221860.39352195128, r=0.01), (datetime.datetime(2001, 11, 23, 0, 0), datetime.datetime(2001, 11, 24, 0, 0)))\n",
    "    With statistic 2.13725887188"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "assert close(result.clusters[0].centre, Disc(x=206471.83133200672, y=207365.95278645432, r=2902.9015483554076))\n",
    "assert close(result.clusters[1].centre, Disc(x=202094.94773067575, y=213132.66867960128, r=0.01))\n",
    "assert close(result.clusters[2].centre, Disc(x=203588.077360351, y=221860.39352195128, r=0.01))\n",
    "\n",
    "assert result.time_ranges[0] == (datetime.datetime(2001,11,22), datetime.datetime(2001,11,24))\n",
    "assert result.time_ranges[1] == (datetime.datetime(2001,11,24), datetime.datetime(2001,11,24))\n",
    "assert result.time_ranges[2] == (datetime.datetime(2001,11,23), datetime.datetime(2001,11,24))\n",
    "\n",
    "assert abs(result.statistics[0] - 3.8454183710604433) < 1e-6\n",
    "assert abs(result.statistics[1] - 3.16420115704) < 1e-6\n",
    "assert abs(result.statistics[2] - 2.13725887188) < 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "max_clusters = trainer.maximise_clusters(result.clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A plot\n",
    "\n",
    "We finish with a plot of the data and the found clusters (the first 5).  We caution that such a plot is misleading-- there is no attempt to visualise the _time stamps_ of the data, and so it is very hard to visualise what is a cluster..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,8))\n",
    "\n",
    "x = np.array([x for d,x,y in data])\n",
    "y = np.array([y for d,x,y in data])\n",
    "\n",
    "dx = np.random.random(size=len(x)) * 100\n",
    "dy = np.random.random(size=len(y)) * 100\n",
    "\n",
    "ax.scatter(x+dx, y+dy, marker=\"+\", linewidth=1, color=\"black\", alpha=0.5)\n",
    "\n",
    "for mic, mac in zip(result.clusters[:5], max_clusters):\n",
    "    c = plt.Circle(mic.centre, mac.radius, alpha=0.3, color=\"red\")\n",
    "    ax.add_artist(c)\n",
    "    c = plt.Circle(mic.centre, mic.radius, alpha=0.3, color=\"blue\")\n",
    "    ax.add_artist(c)\n",
    "    \n",
    "ax.set_aspect(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Does SaTScan look at all discs?\n",
    "\n",
    "Consider the following artificial arrangement of points.  Ordered by the x coordinate, there is (as shown) a disk containing points 0,1,2 but not 3.  However, no disk _which is centred on a point_ can perform this separation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "points = np.array([[.1,1.5],[.2,1],[.9,.2],[1.3,.1],[1.8,1],[1.9,1.3]]).T\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "ax.scatter(points[0], points[1])\n",
    "c = plt.Circle([1,1], 0.9, alpha=0.2, color=\"Red\")\n",
    "ax.add_artist(c)\n",
    "ax.set(xlim=[0,2], ylim=[0,2])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "one = np.datetime64(\"2017-01-01\")\n",
    "two = np.datetime64(\"2017-01-02\")\n",
    "\n",
    "timestamps = [one, two, two, one, two, one]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"artifical1.geo\", \"w\") as geofile:\n",
    "    for i, (x,y) in enumerate(points.T):\n",
    "        print(\"{}\\t{}\\t{}\".format(10000+i, x, y), file=geofile)\n",
    "        \n",
    "with open(\"artifical1.cas\", \"w\") as casefile:\n",
    "    for i, (t) in enumerate(timestamps):\n",
    "        print(\"{}\\t{}\\t{}\".format(10000+i, 1, t), file=casefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = len(timestamps)\n",
    "allsets = [ set(j for j in range(N) if ((i+1)&(2**j))!=0)\n",
    "           for i in range(2**N-1) ]\n",
    "timeranges = [(np.datetime64(\"2017-01-02\"),np.datetime64(\"2017-01-02\")),\n",
    "             (np.datetime64(\"2017-01-01\"),np.datetime64(\"2017-01-02\"))]\n",
    "\n",
    "def print_all(allsets):\n",
    "    lines = []\n",
    "    for space_set in allsets:\n",
    "        for timerange in timeranges:\n",
    "            in_time =set(i for i,t in enumerate(timestamps) if timerange[0]<=t and t<=timerange[1])\n",
    "            expected = len(space_set) * len(in_time) / len(timestamps)\n",
    "            actual = len(space_set.intersection(in_time))\n",
    "            if actual > expected:\n",
    "                lines.append((space_set, timerange, expected, actual,\n",
    "                      statistic(actual, len(timestamps), len(space_set), len(in_time))))\n",
    "    lines.sort(key = lambda tu : tu[4])\n",
    "    for l in lines:\n",
    "        print(l)\n",
    "\n",
    "print_all(allsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from_centred_disks = []\n",
    "for pt in points.T:\n",
    "    dists = np.sqrt(np.sum((pt[:,None] - points)**2, axis=0)) * 1.0001\n",
    "    for d in dists:\n",
    "        s = frozenset(i for i,p in enumerate(points.T) if\n",
    "           np.sqrt(np.sum((pt-p)**2)) <= d)\n",
    "        from_centred_disks.append(s)\n",
    "        \n",
    "from_centred_disks = list(set(from_centred_disks))\n",
    "\n",
    "print_all(from_centred_disks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SaTScan can only be configured to look at spatial and temporal regions with up to 50% of data.  So with 6 points, we should ignore ignore sets containing more than 3 points.\n",
    "\n",
    "- Looking at \"centred disks\" we find that 0.104232 is the greatest statistic, for sets {2,3,4} or {0,1,2} or {1,2,3}.  SaTScan finds {0,1,2}.\n",
    "- Looking at all possible sets, the set {1,2,4} is the best with statistic 0.863046\n",
    "- This is the disk we highlighted above.\n",
    "\n",
    "**Conclusion:** SatScan looks only at spatial regions which are centred on the location of an event.  This can lead to missing \"clusters\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate random data for testing\n",
    "\n",
    "We generate some purely random data, which we shall use of an \"integration test\" of our `stscan` code.\n",
    "\n",
    "While performing comparisons with the SaTScan output, I also noticed that SaTScan does not report \"clusters\" of just one event.  This seems very reasonable, and is now implemented in our code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Generate random data and save\n",
    "N = 30\n",
    "points = np.random.random(size=N*2).reshape(2,N)\n",
    "timestamps = np.datetime64(\"2017-01-01\") + np.random.randint(10, size=N) * np.timedelta64(1, \"D\")\n",
    "\n",
    "timestamps, xcs, ycs = open_cp.data.order_by_time(timestamps, points[0], points[1])\n",
    "points = np.array([xcs, ycs])\n",
    "\n",
    "def write_test_file(basename):\n",
    "    with open(basename + \".geo\", \"w\") as geofile:\n",
    "        for i, (x,y) in enumerate(points.T):\n",
    "            print(\"{}\\t{}\\t{}\".format(10000+i, x, y), file=geofile)\n",
    "\n",
    "    with open(basename + \".cas\", \"w\") as casefile:\n",
    "        for i, (t) in enumerate(timestamps):\n",
    "            print(\"{}\\t{}\\t{}\".format(10000+i, 1, t), file=casefile)\n",
    "\n",
    "import os\n",
    "#write_test_file(os.path.join(\"..\", \"tests\", \"sts_test_data\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read data from file\n",
    "\n",
    "def read_test_file(basename):\n",
    "    coords = []\n",
    "    with open(basename + \".geo\") as geofile:\n",
    "        for line in geofile:\n",
    "            i, x, y = line.split()\n",
    "            coords.append( (float(x), float(y)) )\n",
    "\n",
    "    timestamps = []\n",
    "    with open(basename + \".cas\") as casefile:\n",
    "        for line in casefile:\n",
    "            i, count, t = line.split()\n",
    "            timestamps.append(np.datetime64(t))\n",
    "            \n",
    "    return np.asarray(timestamps), np.asarray(coords).T\n",
    "\n",
    "timestamps, points = read_test_file(os.path.join(\"..\", \"tests\", \"sts_test_data\"))      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.scatter(points[0], points[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer = open_cp.stscan.STSTrainer()\n",
    "trainer.geographic_population_limit = 0.5\n",
    "trainer.geographic_radius_limit = 3000\n",
    "trainer.time_population_limit = 0.5\n",
    "trainer.time_max_interval = datetime.timedelta(days=10)\n",
    "trainer.data = open_cp.TimedPoints.from_coords(timestamps, points[0], points[1])\n",
    "result = trainer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.time_ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result.statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the simulated p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(os.path.join(\"..\",\"tests\",\"sts_test_data.llr.txt\")) as statfile:\n",
    "    satscan_stats = [float(x) for x in statfile]\n",
    "    \n",
    "satscan_stats.sort()\n",
    "plt.plot(satscan_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_stats = trainer.monte_carlo_simulate(runs=9999)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "our_stats.sort()\n",
    "stats = [our_stats[i*9999//99999] for i in range(99999)]\n",
    "plt.plot(satscan_stats)\n",
    "plt.plot(stats)\n",
    "plt.legend([\"SaTScan\", \"Us\"])\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
